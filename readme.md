# LLM Inverse Kinematics

This repository is the base for generating prompts and executing code for testing the [inverse kinematics](https://en.wikipedia.org/wiki/Inverse_kinematics "Inverse Kinematics Wikipedia") generated by LLMs for [serial manipulators](https://en.wikipedia.org/wiki/Serial_manipulator "Serial Manipulators Wikipedia"). Serial manipulators, or robot arms, are a kinematic chain with a single "end effector", and often have six joints as that is what is required to reach all places in a 3D space. This provides a framework to generate an initial text prompt from the data of a robot providing details about its joint structure, along with providing feedback prompts based off of trials to help an LLM improve.

## Significance

- Inverse kinematics are hard to solve and require a great deal of understanding of the subject. An LLM being able to comprehend the structure of a kinematic chain and further solve the inverse kinematics would show a very high degree of understanding and complex problem-solving in a 3D space with advanced mathematical skills.
- Being able to solve inverse kinematics from only a text description of the robot's chain would show the LLM's ability to conceptualize the robot in 3D space without actually being given any images or other visual representation.
- To the best of our knowledge through a search of existing literature, this has never been attempted. [LLMs have been research for motion planning](https://arxiv.org/abs/2403.11552 "LLM3:Large Language Model-based Task and Motion Planning with Motion Failure Reasoning") (meaning, the LLM requests where the robot moves to, but, it does not control the inverse kinematics), but our search of existing literature has not shown any attempts at solving the inverse kinematics itself.

## Background

There are multiple ways to solve inverse kinematics.
1. Numerical/iterative solvers which try to converge to a solution. These are very popular but have the problem of failing to converge by getting stuck in a local minima. Popular libraries such as [IKPy](https://github.com/Phylliade/ikpy "IKPy") use these methods. Even the Robot [Operating System (ROS)](https://www.ros.org "ROS - Robot Operating System") uses the [KDL solver](https://wiki.ros.org/kdl "KDL Solver") which is of this type of solver by default.
   - Pros:
     1. Implementations available in most languages.
     2. Can typically handle a variety of degrees-of-freedom.
   - Cons:
     1. Slow execution time compared to other methods.
     2. Can fail due to getting stuck in a local minima.
     3. Some versions can only solve for position, not the entire transform of position and orientation.
2. Machine learning techniques taken approaches at solving this. [Bio IK](https://d-nb.info/1221720910/34 "Bio IK") is one of the best, and I built [Fusion IK](https://stevenrice.ca/fusion-ik "Fusion IK Demo") on top of it which improves its effectiveness on extended kinematic chains. However, most of these lack repeatability given their evolutionary nature, and repeatability is something we want for robotics.
   - Pros:
     1. Can scale very well across a range of degrees-of-freedom.
     2. The joint move times produced can be optimized to be efficient.
     3. Neural networks and evolutionary solvers are available in most languages.
   - Cons:
     1. Variable and inconsistent results.
     2. Long training times for deep learning methods.
     3. Although neural networks and evolutionary solvers are available in most languages, robot-specific implementations are not.
3. Analytical solvers solve generate closed-form solutions by solving complex equations to complete the inverse kinematics. This is most often done by hand by experts. The only program which can do this is [IKFast](https://moveit.picknik.ai/main/doc/examples/ikfast/ikfast_tutorial.html "MoveIt IKFast") can generate C++ code for six or seven degrees-of-freedom robots in a few minutes but fails beyond that.
   - Pros:
     1. Very fast execution time.
     2. Perfect repeatability.
   - Cons:
     1. [IKFast](https://moveit.picknik.ai/main/doc/examples/ikfast/ikfast_tutorial.html "MoveIt IKFast") is essentially the only option for this, and it is very much tied to specific Linux and ROS versions making it quite hard to use outside of that.
     2. Fails beyond six or seven degrees-of-freedom.

## Goal

- Get an LLM to consistently produce successful inverse kinematics solutions across multiple serial manipulators.
- These could at first be numerical solutions, as even their math is complex.
- However, as numerical solvers already exist in most languages as packages, this would not be very useful for practical use, as it would more or less just show that an LLM can comprehend how to do this method.
- The overall goal would be to get analytical solutions being produced.
- We could compare the effectiveness of the solutions both in terms of their accuracy and execution time.

## Features

- Robots can be parsed and tested with a standard numerical solver.
- You can choose to solve for the entire transform (position and orientation), or just position.
- You can choose to use joint limits or ignore them.
- You can generate initial prompts for LLMs that give the kinematic structure of the robot.
- You can generate feedback prompts based off the results for feeding back to the LLM to try and get it to improve its solution.

## Progress

- GPT-4 has succeeded in solving a 1-DOF arm, but has failed on a 2-DOF arm.
- All other models have failed on everything.
- At the moment, it seems no LLMs can fully understand kinematic chain descriptions and produce inverse kinematic solutions, but, this repository would allow for easily testing any future LLM releases as soon as they happen.
- However, GPT-4 being able to compute even just a 1-DOF arm shows how LLMs are starting to reach this high level of understanding.

## Usage

- "main.py" has all methods.
- "configuration.py" controls what robot and with what settings other methods will use.
- "visualize.py" lets you see and manually control a robot.
- "prompt.py" will output a prompt to the console for you to give to LLMs. The contents of the prompt are composed of a static start and end found in "Prompts/prompt_start.txt" and "Prompts/prompt_end_position.txt" or "Prompts/prompt_end_transform.txt" depending on what is being solved for, and between them a dynamic portion of the prompt is input consisting of information about the robot.
- Once you have a solution from an LLM, under "Solvers", create folders matching the names of the robot under "Models" you are using. Then, create a subfolder for either "Position" or "Transform" depending on what you are solving. Then, create a Python file named after the LLM implementing the function "inverse_kinematics" which takes in a position (or position and orientation if solving for the entire transform) to reach and returns the joint values.
- "test.py" lets you run trails to test the inverse kinematics and generate feedback prompts for the LLM to then use to try and improve the solution.
- "evaluate.py" runs trials across all models and writes them to CSV files.

## Future

- As of now, all prompting and then executing of the code in manual via outputting prompts and results to the console, inputting them to a chat interface for an LLM such as [ChatGPT](http://chatgpt.com, "ChatGPT"), [Gemini](https://gemini.google.com, "Gemini"), or [HuggingChat](https://huggingface.co/chat, "HuggingChat").
- In the future, implementing methods to automatically do this via APIs such as the [OpenAI API](http://platform.openai.com, "OpenAI API") could help more quickly iterate the process of creating and debugging inverse kinematics solutions.